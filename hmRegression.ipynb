{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Add, Conv2D, Conv2DTranspose, concatenate, Cropping2D, MaxPooling2D, Reshape, UpSampling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nkeypoints = 2\n",
    "W = 64\n",
    "H = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2 ... 61 62 63]\n",
      " [ 0  1  2 ... 61 62 63]\n",
      " [ 0  1  2 ... 61 62 63]\n",
      " ...\n",
      " [ 0  1  2 ... 61 62 63]\n",
      " [ 0  1  2 ... 61 62 63]\n",
      " [ 0  1  2 ... 61 62 63]]\n"
     ]
    }
   ],
   "source": [
    "index_map = [j for i in range(512) for j in range(64)]\n",
    "index_map = np.reshape(index_map, newshape=(512,64))\n",
    "print(index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGenerator(tensorflow.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, directory, idxs, img_dict, labels_dict,\n",
    "                 target_size=(512,64), batch_size=1, augment=False,\n",
    "                 transform_dict = None, shuffle=True):\n",
    "\n",
    "        self.directory = directory\n",
    "        self.idxs = idxs\n",
    "        self.img_dict = img_dict\n",
    "        self.labels_dict = labels_dict\n",
    "        self.transform_dict = transform_dict\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augment\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # shuffle indices at the end of each epoch\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle is True:\n",
    "            np.random.shuffle(self.idxs)\n",
    "\n",
    "    # return number of batches per epoch\n",
    "    def __len__(self):\n",
    "\n",
    "        if self.augment is True:\n",
    "            multiplier = 5\n",
    "        else:\n",
    "            multiplier = 1\n",
    "\n",
    "        return int(np.floor(len(self.idxs) * multiplier / self.batch_size))\n",
    "\n",
    "    # check if transformed point is located within image boundaries\n",
    "    def _checkBoundaries(self, p):\n",
    "\n",
    "        # x dimension\n",
    "        if p[0] < 0:\n",
    "            px = 0\n",
    "        elif p[0] > self.target_size[0]:\n",
    "            px = self.target_size[0]\n",
    "        else:\n",
    "            px = p[0]\n",
    "\n",
    "        # y dimension\n",
    "        if p[1] < 0:\n",
    "            py = 0\n",
    "        elif p[1] > self.target_size[1]:\n",
    "            py = self.target_size[1]\n",
    "        else:\n",
    "            py = p[1]\n",
    "\n",
    "        return (int(px), int(py))\n",
    "\n",
    "    # apply shifts, rotations, scaling and flips to original image and keypoints\n",
    "    def _transform_image(self, img, keypoints):\n",
    "\n",
    "        aug_keypoints = []\n",
    "\n",
    "        c = (img.shape[0] // 2, img.shape[1] // 2)\n",
    "\n",
    "        if self.transform_dict['Flip']:\n",
    "            flip = random.choice([True, False])\n",
    "            if flip:\n",
    "                img = cv.flip(img, flipCode=1)\n",
    "\n",
    "        if self.transform_dict['Rotate']:\n",
    "\n",
    "            if self.transform_dict['Scale']:\n",
    "                s = random.uniform(0.7, 1.0)\n",
    "            else:\n",
    "                s = 1.0\n",
    "\n",
    "            r = random.randint(-10, 10)\n",
    "            M_rot = cv.getRotationMatrix2D(center=(img.shape[0] // 2, img.shape[1] // 2), angle=r, scale=s)\n",
    "            img = cv.warpAffine(img, M_rot, (img.shape[0], img.shape[1]), borderMode=cv.BORDER_CONSTANT, borderValue=1)\n",
    "\n",
    "        if self.transform_dict['Shift']:\n",
    "            tx = random.randint(-20, 20)\n",
    "            ty = random.randint(-20, 20)\n",
    "            M_shift = np.array([[1, 0, tx], [0, 1, ty]], dtype=np.float32)\n",
    "            img = cv.warpAffine(img, M_shift, (img.shape[0], img.shape[1]),\n",
    "                                borderMode=cv.BORDER_CONSTANT, borderValue=1)\n",
    "\n",
    "        # transform keypoints\n",
    "        c = (img.shape[0] // 2, img.shape[1] // 2)\n",
    "\n",
    "        for i in range(0, len(keypoints) - 1, 2):\n",
    "\n",
    "            px = keypoints[i]\n",
    "            py = keypoints[i+1]\n",
    "            p = np.array([px, py, 1], dtype=int)\n",
    "\n",
    "            # apply flip\n",
    "            if self.transform_dict['Flip'] and flip:\n",
    "                p[0] = c[0] - (p[0] - c[0])\n",
    "\n",
    "            # apply rotation\n",
    "            if self.transform_dict['Rotate']:\n",
    "                p = np.dot(M_rot, p)\n",
    "\n",
    "            # apply horizontal / vertical shifts\n",
    "            if self.transform_dict['Shift']:\n",
    "                p[0] += tx\n",
    "                p[1] += ty\n",
    "\n",
    "            p = self._checkBoundaries(p)\n",
    "\n",
    "            aug_keypoints.append(p[0])\n",
    "            aug_keypoints.append(p[1])\n",
    "\n",
    "        return img, aug_keypoints\n",
    "\n",
    "    # load image from disk\n",
    "    def _load_image(self, fn):\n",
    "\n",
    "        img = cv.imread(filename=os.path.join(self.directory, fn))\n",
    "        # print(os.path.join(self.directory, fn), img)\n",
    "        # print(fn)\n",
    "        # img = cv.cvtColor(img, cv.COLOR_GRAY2BGR)\n",
    "        # img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img = np.float32(img) / 255\n",
    "\n",
    "        return img\n",
    "\n",
    "    # apply gaussian kernel to image\n",
    "    def _gaussian(self, xL, yL, sigma, H, W):\n",
    "\n",
    "        channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n",
    "        channel = np.array(channel, dtype=np.float32)\n",
    "        channel = np.reshape(channel, newshape=(H, W))\n",
    "\n",
    "        return channel\n",
    "\n",
    "    # convert original image to heatmap\n",
    "    def _convertToHM(self, img, keypoints, sigma=5):\n",
    "\n",
    "        H = img.shape[0]\n",
    "        W = img.shape[1]\n",
    "        nKeypoints = len(keypoints)\n",
    "\n",
    "        img_hm = np.zeros(shape=(H, W, nKeypoints // 2), dtype=np.float32)\n",
    "\n",
    "        for i in range(0, nKeypoints // 2):\n",
    "            x = keypoints[i * 2]\n",
    "            y = keypoints[1 + 2 * i]\n",
    "\n",
    "            channel_hm = self._gaussian(x, y, sigma, H, W)\n",
    "\n",
    "            img_hm[:, :, i] = channel_hm\n",
    "        \n",
    "        img_hm = np.reshape(img_hm, newshape=(img_hm.shape[0]*img_hm.shape[1]*nKeypoints // 2, 1))\n",
    "\n",
    "        return img_hm\n",
    "\n",
    "    # generate batches of scaled images and bounding boxes\n",
    "    def _data_generation(self, idxs):\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for idx in idxs:\n",
    "            img = self._load_image(self.img_dict[idx])\n",
    "            keypoints = self.labels_dict[idx]\n",
    "\n",
    "            if self.augment is True and self.transform_dict:\n",
    "                img, keypoints = self._transform_image(img, keypoints)\n",
    "\n",
    "            img = np.reshape(img, (512, 64, 1))\n",
    "            img_hm = self._convertToHM(img, keypoints)\n",
    "\n",
    "            x.append(img)\n",
    "            y.append(img_hm)\n",
    "\n",
    "        return np.array(x, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "    # return indices for train batches\n",
    "    def _get_train_idxs(self, idx):\n",
    "\n",
    "        # number of batches in original train set\n",
    "        N = int(np.floor(len(self.idxs) / self.batch_size))\n",
    "\n",
    "        # idx exceeds original image indices\n",
    "        if idx > N:\n",
    "\n",
    "            # reset start idx\n",
    "            if idx % N == 0:\n",
    "                reset_idx = 0 #((idx - 1) % N) + 1\n",
    "            else:\n",
    "                reset_idx = idx % N - 1\n",
    "\n",
    "            start = reset_idx * self.batch_size\n",
    "\n",
    "            # end idx\n",
    "            if (reset_idx + 1) * self.batch_size > len(self.idxs):\n",
    "                end = len(self.idxs)\n",
    "            else:\n",
    "                end = (reset_idx + 1) * self.batch_size\n",
    "\n",
    "        # idx is within in original train set\n",
    "        else:\n",
    "            start = idx * self.batch_size\n",
    "            end = (idx + 1) * self.batch_size\n",
    "\n",
    "        return start, end\n",
    "\n",
    "    # return indices for val batches\n",
    "    def _get_val_idxs(self, idx):\n",
    "\n",
    "        if (idx + 1) * self.batch_size > len(self.idxs):\n",
    "            end = len(self.idxs)\n",
    "        else:\n",
    "            end = (idx + 1) * self.batch_size\n",
    "\n",
    "        return idx * self.batch_size, end\n",
    "\n",
    "    # return batch of image data and labels\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.augment is True:\n",
    "            start_batch_idx, end_batch_idx = self._get_train_idxs(idx)\n",
    "        else:\n",
    "            start_batch_idx, end_batch_idx = self._get_val_idxs(idx)\n",
    "\n",
    "        idxs = self.idxs[start_batch_idx:end_batch_idx]\n",
    "        batch_x, batch_y = self._data_generation(idxs)\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_masks(batch_imgs, batch_gt_masks, nrows, ncols, include_preds= False, predictions=None):\n",
    "\n",
    "    if not include_preds:\n",
    "        nrows -= 1\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "\n",
    "    r = -1\n",
    "\n",
    "    for c in range(ncols):\n",
    "\n",
    "        # original image\n",
    "        img = batch_imgs[c]\n",
    "        img = np.reshape(img, newshape=(512,64))\n",
    "        img = np.stack([img,img,img], axis=-1)\n",
    "\n",
    "        # ground-truth mask\n",
    "        gt_mask = batch_gt_masks[c]\n",
    "        gt_mask = np.reshape(gt_mask, newshape=(512,64,2))\n",
    "        gt_mask = np.sum(gt_mask, axis=-1)\n",
    "\n",
    "        axes[0, c].imshow(img)\n",
    "        axes[1, c].imshow(gt_mask)\n",
    "\n",
    "        # prediction mask\n",
    "        if include_preds: \n",
    "            pred_mask = predictions[c]\n",
    "            pred_mask = np.reshape(pred_mask, newshape=(512,64,2))\n",
    "            pred_mask = np.sum(pred_mask, axis=-1)\n",
    "            axes[2, c].imshow(pred_mask)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "train_dir = \"train\"\n",
    "train_csv = \"training.csv\"\n",
    "test_dir = \"test\"\n",
    "test_csv = \"test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(train_csv))\n",
    "df_test = pd.read_csv(os.path.join(test_csv))\n",
    "\n",
    "n_train = df_train['Image'].size\n",
    "n_test = df_test['Image'].size\n",
    "\n",
    "df_kp = df_train.iloc[:,1:5]\n",
    "\n",
    "idxs = []\n",
    "\n",
    "img_dict = {}\n",
    "kp_dict = {}\n",
    "\n",
    "for i in range(n_train):\n",
    "\n",
    "    if True in df_train.iloc[i, 1:5].isna().values:\n",
    "        continue\n",
    "    else:\n",
    "        idxs.append(i)\n",
    "\n",
    "        img_dict[i] = df_train['Image'][i]\n",
    "\n",
    "        # keypoints\n",
    "        kp = df_kp.iloc[i].values.tolist()\n",
    "        kp_dict[i] = kp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data Into Train / Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# of Training Images: 264\n",
      "# of Val Images: 30\n",
      "\n",
      "# of training batches= 264\n",
      "# of validation batches= 3\n",
      "(1, 512, 64, 1)\n",
      "(1, 65536, 1)\n",
      "(8, 512, 64, 1)\n",
      "(8, 65536, 1)\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(idxs)\n",
    "\n",
    "# subset = int(0.1*len(idxs))\n",
    "\n",
    "cutoff_idx = int(0.9*len(idxs))\n",
    "train_idxs = idxs[0:cutoff_idx]\n",
    "val_idxs = idxs[cutoff_idx:len(idxs)]\n",
    "\n",
    "print(\"\\n# of Training Images: {}\".format(len(train_idxs)))\n",
    "print(\"# of Val Images: {}\".format(len(val_idxs)))\n",
    "\n",
    "transform_dict = {\"Flip\": False, \"Shift\": False, \"Scale\": False, \"Rotate\": False}\n",
    "\n",
    "train_gen = MaskGenerator(os.path.join(data_dir, train_dir),\n",
    "                              train_idxs,\n",
    "                              img_dict,\n",
    "                              kp_dict,\n",
    "                              transform_dict=transform_dict,\n",
    "                              augment=False, \n",
    "                              batch_size=1)\n",
    "\n",
    "val_gen = MaskGenerator(os.path.join(data_dir, train_dir),\n",
    "                            val_idxs,\n",
    "                            img_dict,\n",
    "                            kp_dict,\n",
    "                            augment=False,\n",
    "                            batch_size=8)\n",
    "\n",
    "print(\"\\n# of training batches= %d\" % len(train_gen))\n",
    "print(\"# of validation batches= %d\" % len(val_gen))\n",
    "train_imgs, train_masks = train_gen[0]\n",
    "print(train_imgs.shape)\n",
    "print(train_masks.shape)\n",
    "# show_masks(train_imgs[0:4], train_masks[0:4], nrows=3, ncols=4)\n",
    "\n",
    "val_imgs, val_masks= val_gen[0]\n",
    "print(val_imgs.shape)\n",
    "print(val_masks.shape)\n",
    "# show_masks(val_imgs[0:4], val_masks[0:4], nrows=3, ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Output\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 512, 64, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Block1_Conv1 (Conv2D)          (None, 512, 64, 4)   40          ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " Block1_Conv2 (Conv2D)          (None, 512, 64, 4)   148         ['Block1_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block1_Pool1 (MaxPooling2D)    (None, 256, 32, 4)   0           ['Block1_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block2_Conv1 (Conv2D)          (None, 256, 32, 8)   296         ['Block1_Pool1[0][0]']           \n",
      "                                                                                                  \n",
      " Block2_Conv2 (Conv2D)          (None, 256, 32, 8)   584         ['Block2_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block2_Pool1 (MaxPooling2D)    (None, 128, 16, 8)   0           ['Block2_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block3_Conv1 (Conv2D)          (None, 128, 16, 16)  1168        ['Block2_Pool1[0][0]']           \n",
      "                                                                                                  \n",
      " Block3_Conv2 (Conv2D)          (None, 128, 16, 16)  2320        ['Block3_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block3_Pool1 (MaxPooling2D)    (None, 64, 8, 16)    0           ['Block3_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block4_Conv1 (Conv2D)          (None, 64, 8, 32)    4640        ['Block3_Pool1[0][0]']           \n",
      "                                                                                                  \n",
      " Block4_Conv2 (Conv2D)          (None, 64, 8, 32)    9248        ['Block4_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block4_Pool1 (MaxPooling2D)    (None, 32, 4, 32)    0           ['Block4_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block5_Conv1 (Conv2D)          (None, 32, 4, 64)    18496       ['Block4_Pool1[0][0]']           \n",
      "                                                                                                  \n",
      " Block5_Conv2 (Conv2D)          (None, 32, 4, 64)    36928       ['Block5_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block6_ConvT1 (Conv2DTranspose  (None, 64, 8, 32)   8224        ['Block5_Conv2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Block6_Concat1 (Concatenate)   (None, 64, 8, 64)    0           ['Block6_ConvT1[0][0]',          \n",
      "                                                                  'Block4_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block6_Conv1 (Conv2D)          (None, 64, 8, 32)    18464       ['Block6_Concat1[0][0]']         \n",
      "                                                                                                  \n",
      " Block6_Conv2 (Conv2D)          (None, 64, 8, 32)    9248        ['Block6_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block7_ConvT1 (Conv2DTranspose  (None, 128, 16, 16)  2064       ['Block6_Conv2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Block7_Concat1 (Concatenate)   (None, 128, 16, 32)  0           ['Block7_ConvT1[0][0]',          \n",
      "                                                                  'Block3_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block7_Conv1 (Conv2D)          (None, 128, 16, 16)  4624        ['Block7_Concat1[0][0]']         \n",
      "                                                                                                  \n",
      " Block7_Conv2 (Conv2D)          (None, 128, 16, 16)  2320        ['Block7_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block8_ConvT1 (Conv2DTranspose  (None, 256, 32, 8)  520         ['Block7_Conv2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Block8_Concat1 (Concatenate)   (None, 256, 32, 16)  0           ['Block8_ConvT1[0][0]',          \n",
      "                                                                  'Block2_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block8_Conv1 (Conv2D)          (None, 256, 32, 8)   1160        ['Block8_Concat1[0][0]']         \n",
      "                                                                                                  \n",
      " Block8_Conv2 (Conv2D)          (None, 256, 32, 8)   584         ['Block8_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " Block9_ConvT1 (Conv2DTranspose  (None, 512, 64, 4)  132         ['Block8_Conv2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Block9_Concat1 (Concatenate)   (None, 512, 64, 8)   0           ['Block9_ConvT1[0][0]',          \n",
      "                                                                  'Block1_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " Block9_Conv1 (Conv2D)          (None, 512, 64, 4)   292         ['Block9_Concat1[0][0]']         \n",
      "                                                                                                  \n",
      " Block9_Conv2 (Conv2D)          (None, 512, 64, 4)   148         ['Block9_Conv1[0][0]']           \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 512, 64, 2)   10          ['Block9_Conv2[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 65536, 1)     0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 121,658\n",
      "Trainable params: 121,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def UNET(input_shape):\n",
    "    def downsample_block(x, block_num, n_filters, pooling_on=True):\n",
    "\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "                   name=\"Block\" + str(block_num) + \"_Conv1\")(x)\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "                   name=\"Block\" + str(block_num) + \"_Conv2\")(x)\n",
    "        skip = x\n",
    "\n",
    "        if pooling_on is True:\n",
    "            x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', name=\"Block\" + str(block_num) + \"_Pool1\")(x)\n",
    "\n",
    "        return x, skip\n",
    "\n",
    "    def upsample_block(x, skip, block_num, n_filters):\n",
    "\n",
    "        x = Conv2DTranspose(n_filters, kernel_size=(2, 2), strides=2, padding='valid', activation='relu',\n",
    "                            name=\"Block\" + str(block_num) + \"_ConvT1\")(x)\n",
    "        x = concatenate([x, skip], axis=-1, name=\"Block\" + str(block_num) + \"_Concat1\")\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "                   name=\"Block\" + str(block_num) + \"_Conv1\")(x)\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "                   name=\"Block\" + str(block_num) + \"_Conv2\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    input = Input(input_shape, name=\"Input\")\n",
    "\n",
    "    # downsampling\n",
    "    x, skip1 = downsample_block(input, 1, 4)\n",
    "    x, skip2 = downsample_block(x, 2, 8)\n",
    "    x, skip3 = downsample_block(x, 3, 16)\n",
    "    x, skip4 = downsample_block(x, 4, 32)\n",
    "    x, _ = downsample_block(x, 5, 64, pooling_on=False)\n",
    "\n",
    "    # upsampling\n",
    "    x = upsample_block(x, skip4, 6, 32)\n",
    "    x = upsample_block(x, skip3, 7, 16)\n",
    "    x = upsample_block(x, skip2, 8, 8)\n",
    "    x = upsample_block(x, skip1, 9, 4)\n",
    "\n",
    "    output = Conv2D(2, kernel_size=(1, 1), strides=1, padding='valid', activation='linear', name=\"output\")(x)\n",
    "    output = Reshape(target_shape=(H*W*Nkeypoints,1))(output)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output, name=\"Output\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "unet = UNET(input_shape=(512, 64, 1))\n",
    "print(unet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, 96, 96, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 96, 96, 64)   640         Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 96, 96, 64)   36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 48, 48, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 48, 48, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 48, 48, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 24, 24, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 24, 24, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 24, 24, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 24, 24, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 12, 12, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 12, 12, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 12, 12, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 12, 12, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 6, 6, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 6, 6, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 6, 6, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 3, 3, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 3, 3, 4096)   2101248     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "preds_pool4 (Conv2D)            (None, 6, 6, 15)     7695        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 3, 3, 15)     61455       conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "preds_pool3 (Conv2D)            (None, 12, 12, 15)   3855        block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ConvT_pool4 (Conv2DTranspose)   (None, 12, 12, 15)   915         preds_pool4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ConvT_conv7 (Conv2DTranspose)   (None, 12, 12, 15)   3615        conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 12, 12, 15)   0           preds_pool3[0][0]                \n",
      "                                                                 ConvT_pool4[0][0]                \n",
      "                                                                 ConvT_conv7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "convT_fusion (Conv2DTranspose)  (None, 96, 96, 15)   14415       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output (Conv2D)                 (None, 96, 96, 15)   240         convT_fusion[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 138240, 1)    0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,906,974\n",
      "Trainable params: 16,906,974\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x, nconvs, n_filters, block_name, wd=None):\n",
    "    for i in range(nconvs):\n",
    "        x = Conv2D(n_filters, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "                   kernel_regularizer=wd, name=block_name + \"_conv\" + str(i + 1))(x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', name=block_name + \"_pool\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def FCN8(input_shape):\n",
    "    input = Input(shape=input_shape, name=\"Input\")\n",
    "\n",
    "    # Block 1\n",
    "    x = conv_block(input, nconvs=2, n_filters=64, block_name=\"block1\")\n",
    "\n",
    "    # Block 2\n",
    "    x = conv_block(x, nconvs=2, n_filters=128, block_name=\"block2\")\n",
    "\n",
    "    # Block 3\n",
    "    pool3 = conv_block(x, nconvs=3, n_filters=256, block_name=\"block3\")\n",
    "\n",
    "    # Block 4\n",
    "    pool4 = conv_block(pool3, nconvs=3, n_filters=512, block_name=\"block4\")\n",
    "\n",
    "    # Block 5\n",
    "    x = conv_block(pool4, nconvs=3, n_filters=512, block_name=\"block5\")\n",
    "\n",
    "    # convolution 6\n",
    "    x = Conv2D(4096, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"relu\", name=\"conv6\")(x)\n",
    "\n",
    "    # convolution 7\n",
    "    x = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"relu\", name=\"conv7\")(x)\n",
    "\n",
    "    # upsampling\n",
    "    preds_pool3 = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", name=\"preds_pool3\")(pool3)\n",
    "    preds_pool4 = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", name=\"preds_pool4\")(pool4)\n",
    "    up_pool4 = Conv2DTranspose(filters=15, kernel_size=2, strides=2, activation=\"relu\", name=\"ConvT_pool4\")(preds_pool4)\n",
    "    up_conv7 = Conv2DTranspose(filters=15, kernel_size=4, strides=4, activation=\"relu\", name=\"ConvT_conv7\")(x)\n",
    "\n",
    "    fusion = Add()([preds_pool3, up_pool4, up_conv7])\n",
    "\n",
    "    output = Conv2DTranspose(filters=15, kernel_size=8, strides=8, activation='relu', name=\"convT_fusion\")(fusion)\n",
    "    output = Conv2D(15, kernel_size=(1, 1), strides=1, padding=\"same\", activation=\"linear\", name=\"output\")(output)\n",
    "    output = Reshape(target_shape=(H*W*Nkeypoints, 1))(output)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output, name=\"FCN8\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "fcn = FCN8(input_shape=(96, 96, 1))\n",
    "\n",
    "print(fcn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(ytrue, ypred, smooth=1e-5):\n",
    "\n",
    "    intersection = K.sum(K.abs(ytrue*ypred), axis=-1)\n",
    "    union = K.sum(K.abs(ytrue)+K.abs(ypred), axis=-1)\n",
    "    jac = (intersection + smooth) / (union-intersection+smooth)\n",
    "\n",
    "    return K.mean(jac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    channel_loss = K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "    total_loss = K.mean(channel_loss, axis=-1)\n",
    "    print(total_loss.shape)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(wts_fn, csv_fn, patience=5, enable_save_wts = True):\n",
    "\n",
    "    cbks = []\n",
    "\n",
    "    # early stopping\n",
    "    early_stopper = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    cbks.append(early_stopper)\n",
    "\n",
    "    # model checkpoint\n",
    "    if enable_save_wts is True:\n",
    "        model_chpt = ModelCheckpoint(filepath=wts_fn,\n",
    "                                     monitor='val_loss',\n",
    "                                     verbose=1,\n",
    "                                     save_weights_only=True,\n",
    "                                     save_best_only=True,\n",
    "                                     period=patience)\n",
    "\n",
    "        cbks.append(model_chpt)\n",
    "    \n",
    "    # csv logger\n",
    "    csv_logger = CSVLogger(csv_fn)\n",
    "    cbks.append(csv_logger)\n",
    "\n",
    "    return cbks\n",
    "\n",
    "\n",
    "\n",
    "def trainModel(model, model_name, loss_type, n_epochs, old_lr, new_lr, load_saved_wts = False):\n",
    "\n",
    "    if load_saved_wts is True:\n",
    "        wts_fn = model_name + \"_lr=\" + str(old_lr) + \".h5\"\n",
    "        model.load_weights(wts_fn)\n",
    "    \n",
    "    wts_fn = model_name + \"_lr=\" + str(new_lr) + \".h5\"\n",
    "    csv_fn = model_name + \"_lr=\" + str(new_lr) + \".csv\"\n",
    "    cbks = create_callbacks(wts_fn, csv_fn)\n",
    "    \n",
    "    optim = RMSprop(learning_rate=new_lr)\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optim, metrics=None)\n",
    "    print(\"compile success\")\n",
    "    model.fit_generator(generator=train_gen,\n",
    "                        validation_data=val_gen,\n",
    "                        epochs=n_epochs,\n",
    "                        callbacks=cbks)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = \"mse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = trainModel(fcn, \"fcn\", loss_type, n_epochs=20, old_lr=1e-3, new_lr=1e-3, load_saved_wts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "compile success\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_9260\\1946539614.py:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator=train_gen,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "unet = trainModel(unet, \"unet\", loss_type, n_epochs=20, old_lr=1e-3, new_lr=1e-3, load_saved_wts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskToKeypoints(mask):\n",
    "    # mask = np.reshape(mask, newshape=(96,96))\n",
    "    kp = np.unravel_index(np.argmax(mask, axis=None), dims=(512,64))\n",
    "    return kp[1], kp[0]\n",
    "\n",
    "def findCoordinates(mask):\n",
    "\n",
    "    hm_sum = np.sum(mask)\n",
    "\n",
    "    index_map = [j for i in range(512) for j in range(64)]\n",
    "    \n",
    "    index_map = np.reshape(index_map, newshape=(512,64))\n",
    "    x_score_map = mask * index_map / hm_sum\n",
    "    y_score_map = mask.dot(np.transpose(index_map)) / hm_sum\n",
    "\n",
    "    px = np.sum(np.sum(x_score_map, axis=None))\n",
    "    py = np.sum(np.sum(y_score_map, axis=None))\n",
    "\n",
    "    return px, py\n",
    "\n",
    "\n",
    "def calcKeypoints(model, gen):\n",
    "    kps_gt = []\n",
    "    kps_preds = []\n",
    "    nbatches = len(gen)\n",
    "\n",
    "    for i in range(nbatches+1):\n",
    "        # print(\"\\nBatch {}\".format(i))\n",
    "        imgs, batch_gt = gen[i]\n",
    "        batch_preds = model.predict_on_batch(imgs)\n",
    "        n_imgs = imgs.shape[0]\n",
    "        # print(\"\\t# of Images {}\".format(n_imgs))\n",
    "        for j in range(n_imgs):\n",
    "            mask_gt = batch_gt[j]\n",
    "            print(mask_gt)\n",
    "            mask_gt = np.reshape(mask_gt, newshape=(512, 64, 2))\n",
    "            mask_pred = batch_preds[j]\n",
    "            mask_pred = np.reshape(mask_pred, newshape=(512, 64, 2))\n",
    "            nchannels = mask_gt.shape[-1]\n",
    "            # print(nchannels)\n",
    "            gt_list = []\n",
    "            pred_list = []\n",
    "\n",
    "            for k in range(nchannels):\n",
    "                xgt, ygt = findCoordinates(mask_gt[:, :, k]) # maskToKeypoints(mask_gt[:, :, k])\n",
    "                xpred, ypred = findCoordinates(mask_pred[:, :, k])  # maskToKeypoints(mask_pred[:, :, k])\n",
    "\n",
    "                gt_list.append(xgt)\n",
    "                gt_list.append(ygt)\n",
    "\n",
    "                pred_list.append(xpred)\n",
    "                pred_list.append(ypred)\n",
    "\n",
    "            kps_gt.append(gt_list)\n",
    "            kps_preds.append(pred_list)\n",
    "    \n",
    "\n",
    "    return np.array(kps_gt, dtype=np.float32), np.array(kps_preds, dtype=np.float32)\n",
    "\n",
    "\n",
    "def calcRMSError(kps_gt, kps_preds):\n",
    "\n",
    "    N = kps_gt.shape[0] * (kps_gt.shape[-1] // 2)\n",
    "    error = np.sqrt(np.sum((kps_gt-kps_preds)**2)/N)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_keypoints(name, batch_imgs, batch_labels, nrows, ncols, predictions=None):\n",
    "\n",
    "    def draw_keypoints(img, keypoints, col):\n",
    "        # print(\"\\n{}\".format(len(keypoints)))\n",
    "        for i in range(0, len(keypoints)-1, 2):\n",
    "            # print(i)\n",
    "            kpx = int(keypoints[i])\n",
    "            kpy = int(keypoints[i+1])\n",
    "            img = cv.circle(img, center=(kpx,kpy), radius=2, color=col, thickness=2)\n",
    "\n",
    "        return img\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "\n",
    "    r = -1\n",
    "\n",
    "    for i in range(len(batch_imgs)):\n",
    "\n",
    "        img = batch_imgs[i]\n",
    "        img = np.reshape(img, newshape=(512, 64))\n",
    "        img = np.stack([img,img,img], axis=-1)\n",
    "\n",
    "        c = i % ncols\n",
    "\n",
    "        if i % ncols == 0:\n",
    "            r += 1\n",
    "\n",
    "        # draw ground-truth keypoints on image\n",
    "        if batch_labels is not None:\n",
    "            img = draw_keypoints(img, batch_labels[i], col=(0,0,255))\n",
    "\n",
    "        # draw predicted keypoints on image\n",
    "        if predictions is not None:\n",
    "            img = draw_keypoints(img, predictions[i], col=(255,0,0))\n",
    "        cv.imshow(name, img)\n",
    "        # axes[r, c].imshow(img)\n",
    "    # plt.savefig(name)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize All Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAllMasks(img_mask, name, nrows=3, ncols=5):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "\n",
    "    r = -1\n",
    "\n",
    "    for i in range(img_mask.shape[-1]):\n",
    "\n",
    "        img = img_mask[:, :, i]\n",
    "        # print(img.shape)\n",
    "        img = np.reshape(img, newshape=(512,64))\n",
    "        img = np.stack([img,img,img], axis=-1)\n",
    "\n",
    "        c = i % ncols\n",
    "\n",
    "        if i % ncols == 0:\n",
    "            r += 1\n",
    "        cv.imshow(name, img)\n",
    "        cv.waitKey(0)\n",
    "        # axes[r, c].imshow(img)\n",
    "    # plt.figure(figsize=(12,12))\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative Mask Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = val_gen[0]\n",
    "fcn.load_weights(\"fcn_lr=0.001.h5\")\n",
    "preds = fcn.predict_on_batch(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(masks.shape)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(imgs[0:3], masks[0:3], nrows=3, ncols=3, include_preds=True, predictions = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask = masks[1]\n",
    "gt_mask = np.reshape(gt_mask, newshape=(96,96,15))\n",
    "showAllMasks(gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = preds[1]\n",
    "pred_mask = np.reshape(pred_mask, newshape=(96,96,15))\n",
    "showAllMasks(pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get keypoints from masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_gt, kps_preds = calcKeypoints(fcn, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kps_preds.shape)\n",
    "print(kps_gt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative keypoint results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(imgs[0:6], kps_gt[0:6], nrows=2, ncols=3, predictions=kps_preds[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_error = calcRMSError(kps_gt, kps_preds)\n",
    "print(\"Validation RMS Error = {}\".format(rms_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative Mask Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, masks = val_gen[0]\n",
    "unet.load_weights(\"unet_lr=0.001.h5\")\n",
    "preds = unet.predict_on_batch(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 65536, 1)\n",
      "(8, 65536, 1)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "print(masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_masks(imgs[0:3], masks[0:3], nrows=3, ncols=3, include_preds=True, predictions = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gt_mask = masks[1]\n",
    "gt_mask = np.reshape(gt_mask, newshape=(512,64,2))\n",
    "showAllMasks(gt_mask, 'gt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = preds[1]\n",
    "pred_mask = np.reshape(pred_mask, newshape=(512,64,2))\n",
    "showAllMasks(pred_mask, 'pr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Keypoints from Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_gt, kps_preds = calcKeypoints(unet, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 4)\n",
      "(30, 4)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "print(kps_preds.shape)\n",
    "print(kps_gt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative keypoint results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\test\\facial-keypoints-detection\\hmRegression.ipynb 셀 55\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/test/facial-keypoints-detection/hmRegression.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m show_keypoints(\u001b[39m'\u001b[39m\u001b[39mkp.png\u001b[39m\u001b[39m'\u001b[39m, imgs[\u001b[39m0\u001b[39m:\u001b[39m6\u001b[39m], kps_gt[\u001b[39m0\u001b[39m:\u001b[39m6\u001b[39m], nrows\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, ncols\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, predictions\u001b[39m=\u001b[39mkps_preds[\u001b[39m0\u001b[39m:\u001b[39m6\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'show_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "show_keypoints('kp.png', imgs[0:6], kps_gt[0:6], nrows=2, ncols=3, predictions=kps_preds[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   252.7494  129199.89       252.90744 129292.734  ]\n"
     ]
    }
   ],
   "source": [
    "print(kps_preds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   251.08148 128542.73       250.40453 128230.39   ]\n"
     ]
    }
   ],
   "source": [
    "print(kps_gt[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate RMS Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMS Error = 914.1658492855659\n"
     ]
    }
   ],
   "source": [
    "rms_error = calcRMSError(kps_gt, kps_preds)\n",
    "print(\"Validation RMS Error = {}\".format(rms_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idxs = np.arange(0,1782)\n",
    "random.shuffle(test_idxs)\n",
    "\n",
    "Ntest = 32\n",
    "test_imgs = []\n",
    "for i in range(Ntest):\n",
    "    fn=  \"test\"+str(test_idxs[i])+\".png\"\n",
    "    \n",
    "    img = cv.imread(os.path.join(data_dir, test_dir, fn))\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    img = np.float32(img) / 255\n",
    "    img = np.reshape(img, newshape=(512,64,1))\n",
    "                    \n",
    "    test_imgs.append(img)\n",
    "\n",
    "test_imgs = np.array(test_imgs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTestKeypoints(preds):\n",
    "    \n",
    "    kps_preds = []\n",
    "    npreds = len(preds)\n",
    "\n",
    "    for i in range(npreds):\n",
    "        mask_pred = preds[i]\n",
    "        mask_pred = np.reshape(mask_pred, newshape=(96, 96, 15))\n",
    "        nchannels = mask_pred.shape[-1]\n",
    "        \n",
    "        pred_list = []\n",
    "\n",
    "        for k in range(nchannels):\n",
    "            xpred, ypred = findCoordinates(mask_pred[:, :, k])  # maskToKeypoints(mask_pred[:, :, k])\n",
    "\n",
    "            pred_list.append(xpred)\n",
    "            pred_list.append(ypred)\n",
    "\n",
    "            kps_preds.append(pred_list)\n",
    "    \n",
    "\n",
    "    return np.array(kps_preds, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCN-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_preds = fcn.predict_on_batch(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(test_imgs[0:4], fcn_preds[0:4], nrows=3, ncols=4, include_preds=False, predictions = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_kps = calcTestKeypoints(fcn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_preds = unet.predict_on_batch(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_masks(test_imgs[0:4], unet_preds[0:4], nrows=3, ncols=4, include_preds=False, predictions = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_kps = calcTestKeypoints(fcn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCN-8 vs. UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_keypoints(test_imgs[0:6], fcn_kps, nrows=2, ncols=3, predictions=unet_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b46b49828c783ce36a3f5dcaa7ce5f44d815cc67107fb2588959dbeedda95c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
